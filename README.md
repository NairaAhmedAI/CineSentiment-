# ğŸ¬ Sentiment Analysis on IMDB Movie Reviews  

## ğŸ“Œ Overview  
This project focuses on **Sentiment Analysis** of IMDB movie reviews, a classic **Natural Language Processing (NLP)** task.  
The main objective is to classify each review as either **Positive** or **Negative** by building a complete pipeline that covers:  

- Data Collection  
- Text Preprocessing  
- Machine Learning & Deep Learning Models (next steps)  

By leveraging NLP techniques, we aim to transform raw unstructured text into clean and meaningful representations that can be used for predictive modeling.  

---

## ğŸ“Š Dataset  
We used the **IMDB Dataset of 50K Movie Reviews**, which contains **25,000 positive** and **25,000 negative** reviews.  
This dataset is widely used for benchmarking sentiment classification models.  

ğŸ“¥ Dataset link: [IMDB 50K Movie Reviews - Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)  

---

## ğŸ›  Data Preprocessing  

Preprocessing is a critical step in NLP as raw text is often noisy and inconsistent. We applied several transformations to prepare the dataset:  

### 1ï¸âƒ£ Lowercasing  
All reviews were converted to lowercase to maintain consistency and avoid duplication caused by case sensitivity.  

### 2ï¸âƒ£ Label Encoding  
The target variable (**sentiment**) was encoded into numeric values:  
- `0` â†’ Negative  
- `1` â†’ Positive  

### 3ï¸âƒ£ Cleaning (Regex-based)  
- Removed **emojis** and **hashtags**  
- Removed HTML tags such as `<br>`  
- Normalized text by stripping unnecessary characters  

### 4ï¸âƒ£ Tokenization & Stopword Removal  
Using **NLTK**, we split sentences into individual tokens (words).  
Stopwords (e.g., *is, the, and*) were removed to reduce noise, but **negation words** (e.g., *not, no*) were kept as they strongly influence sentiment.  

### 5ï¸âƒ£ Lemmatization with POS Tagging  
- Applied **Part-of-Speech (POS) tagging** to identify word categories (noun, verb, adjective, adverb).  
- Used **WordNet Lemmatizer** from NLTK to reduce words to their base form (e.g., *running â†’ run*, *better â†’ good*).  

This step ensures that semantically similar words are treated the same way, improving model generalization.  

---

## ğŸ”‘ Why NLTK?  
The **Natural Language Toolkit (NLTK)** is a powerful and widely-used Python library for NLP.  
It provides tools for:  
- Tokenization  
- Stopword filtering  
- POS tagging  
- Lemmatization  
- Corpora and lexical resources (WordNet)  

Its flexibility and ease of use make it an excellent choice for preprocessing in text classification projects like this one.  

---

ğŸ“Œ *Next steps: Feature extraction (TF-IDF, Word Embeddings) and building Machine Learning & Deep Learning models.*  


ğŸ”¹ Logistic Regression â†’ Balanced, robust & interpretable

ğŸ”¹ SVM â†’ Best trade-off between accuracy & generalization â†’ â­ Recommended model

ğŸ”¹ Random Forest â†’ Useful for feature importance & non-linear patterns
